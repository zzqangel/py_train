{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# filepath = 'xlsdir/train_all_int.xls'\n",
    "\n",
    "# df = pd.read_excel(filepath, skiprows=70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(len(df))\n",
    "# dds = df.head()\n",
    "# print(dds)\n",
    "# print(len(dds))\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据进行切割，第一列切割为Y，其余列切割为X\n",
    "# print(\"第一列\", dds.iloc[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"xlsdir/train_all.csv\",\"r\")\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "max_columns_count = 0\n",
    "max_line_length = 0\n",
    "total_columns_count = 0\n",
    "x_columns_limit = 1000\n",
    "for i in range(len(lines)):\n",
    "    # if i > 20:\n",
    "    #     break\n",
    "    line = lines[i]\n",
    "    line_length = len(line)\n",
    "    if line_length > max_line_length:\n",
    "        max_line_length = line_length\n",
    "    line_arr = line.split(',')\n",
    "    x_arr = line_arr[1:]\n",
    "    y = line_arr[:1]\n",
    "    x_columns_count = len(x_arr)\n",
    "    total_columns_count += x_columns_count\n",
    "    while x_columns_count > x_columns_limit:\n",
    "        X.append(x_arr[:x_columns_limit])\n",
    "        Y.append(y)\n",
    "        x_arr = x_arr[x_columns_limit:]\n",
    "        x_columns_count = len(x_arr)\n",
    "        if x_columns_count > max_columns_count:\n",
    "            max_columns_count = x_columns_count\n",
    "    # total_columns_count += x_columns_count\n",
    "\n",
    "    X.append(x_arr)\n",
    "    x_columns_count = len(x_arr)\n",
    "    if x_columns_count > max_columns_count:\n",
    "        max_columns_count = x_columns_count\n",
    "    Y.append(y)\n",
    "    # print(lines[i])\n",
    "    # for s in line_arr:\n",
    "    #     n = int(s)\n",
    "        # print(int(s))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_2 = []\n",
    "for arr in X:\n",
    "    arr_2 = []\n",
    "    for s in arr:\n",
    "        i = int(s)\n",
    "        arr_2.append(i)\n",
    "    X_2.append(arr_2)\n",
    "X = X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_columns_count = 0\n",
    "for arr in X:\n",
    "    if len(arr) > max_columns_count:\n",
    "        max_columns_count = len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103123\n",
      "103123\n",
      "1000\n",
      "43822\n",
      "266.73552941632806\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(Y))\n",
    "print(max_columns_count)\n",
    "print(max_line_length)\n",
    "print(total_columns_count/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def arr_append_0(append_arr, append_limit):\n",
    "    arr_length = len(append_arr)\n",
    "    if arr_length < append_limit:\n",
    "        append_range = append_limit - len(append_arr)\n",
    "        for _ in range(append_range):\n",
    "            append_arr.append(0)\n",
    "    return append_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# 数组补0\n",
    "\n",
    "for arr in X:\n",
    "    arr = arr_append_0(arr, x_columns_limit)\n",
    "\n",
    "for arr in X[:10]:\n",
    "    print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 103123 总长度\n",
    "# X dim 1000\n",
    "# Y dim 1\n",
    "\n",
    "# 其中划分80000，做训练集\n",
    "# 划分10000，做测试集\n",
    "# 划分10000，做验证集\n",
    "# 循环训练\n",
    "total_row_count = len(X)\n",
    "train_row_count = 80000\n",
    "test_row_count = 10000\n",
    "validate_row_count = total_row_count - train_row_count - test_row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Y转换为枚举类型\n",
    "# info:1\n",
    "# warn:2\n",
    "# debug:3\n",
    "# error:4\n",
    "# other:5\n",
    "Y_2 = []\n",
    "for s in Y:\n",
    "    i = 5\n",
    "    if 'info' == s[0].strip().lower():\n",
    "       i = 1\n",
    "    elif 'warn' == s[0].strip().lower():\n",
    "       i = 2\n",
    "    elif 'debug' == s[0].strip().lower():\n",
    "       i = 3\n",
    "    elif 'error' == s[0].strip().lower():\n",
    "       i = 4\n",
    "    Y_2.append(i)\n",
    "Y = Y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:train_row_count + test_row_count]\n",
    "X_test = X[train_row_count:train_row_count + test_row_count]\n",
    "X_validate = X[train_row_count + test_row_count:]\n",
    "X_train_data = tf.convert_to_tensor(X_train)\n",
    "print(X_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test_data = tf.convert_to_tensor(X_test)\n",
    "X_validate_data = tf.convert_to_tensor(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = Y[:train_row_count + test_row_count]\n",
    "Y_train_data = tf.convert_to_tensor(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_depth = 5\n",
    "# 不做转型会报 Could not find valid device for node 的异常\n",
    "Y_train_data = tf.cast(Y_train_data, tf.int32)\n",
    "Y_train_data = tf.one_hot(Y_train_data, one_hot_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_test = Y[train_row_count:train_row_count + test_row_count]\n",
    "Y_test_data = tf.convert_to_tensor(Y_test)\n",
    "Y_validate = Y[train_row_count + test_row_count:]\n",
    "Y_validate_data = tf.convert_to_tensor(Y_validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 不做转型会报 Could not find valid device for node 的异常\n",
    "Y_test_data = tf.cast(Y_test_data, tf.int32)\n",
    "Y_test_data = tf.one_hot(Y_test_data, one_hot_depth)\n",
    "\n",
    "# 不做转型会报 Could not find valid device for node 的异常\n",
    "Y_validate_data = tf.cast(Y_validate_data, tf.int32)\n",
    "Y_validate_data = tf.one_hot(Y_validate_data, one_hot_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置checkpoint\n",
    "check_point_path = 'checkpoint/train_1'\n",
    "import os\n",
    "if not os.path.exists(check_point_path) or os.path.isfile(check_point_path):\n",
    "    os.mkdir(check_point_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_1_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=check_point_path,\n",
    "    # save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gru_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(input_dim=1000,\n",
    "                         output_dim=32,\n",
    "                         input_length=1000,\n",
    "                         ),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(\n",
    "            512,\n",
    "            activation='ReLU'\n",
    "        ),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GRU(32, return_sequences=True),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GRU(one_hot_depth, activation='sigmoid', return_sequences=False)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                 loss=keras.losses.BinaryCrossentropy(),\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1000, 32)          1307808   \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 1000, 32)          6336      \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 5)                 585       \n",
      "=================================================================\n",
      "Total params: 1,314,729\n",
      "Trainable params: 1,314,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = gru_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1266/1266 [==============================] - 1212s 958ms/step - loss: 0.1648 - accuracy: 0.8400 - val_loss: 0.0354 - val_accuracy: 0.9709\n",
      "Epoch 2/10\n",
      "1266/1266 [==============================] - 1218s 962ms/step - loss: 0.0282 - accuracy: 0.9818 - val_loss: 0.0151 - val_accuracy: 0.9947\n",
      "Epoch 3/10\n",
      "1266/1266 [==============================] - 1220s 964ms/step - loss: 0.0158 - accuracy: 0.9900 - val_loss: 0.0471 - val_accuracy: 0.9768\n",
      "Epoch 4/10\n",
      "1266/1266 [==============================] - 1218s 962ms/step - loss: 0.0136 - accuracy: 0.9912 - val_loss: 0.0075 - val_accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "1266/1266 [==============================] - 1219s 963ms/step - loss: 0.0105 - accuracy: 0.9929 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "1266/1266 [==============================] - 1218s 962ms/step - loss: 0.0101 - accuracy: 0.9930 - val_loss: 0.0440 - val_accuracy: 0.9596\n",
      "Epoch 7/10\n",
      "1266/1266 [==============================] - 1220s 964ms/step - loss: 0.0076 - accuracy: 0.9950 - val_loss: 0.0126 - val_accuracy: 0.9937\n",
      "Epoch 8/10\n",
      "1266/1266 [==============================] - 1221s 964ms/step - loss: 0.0079 - accuracy: 0.9949 - val_loss: 0.0186 - val_accuracy: 0.9742\n",
      "Epoch 9/10\n",
      " 317/1266 [======>.......................] - ETA: 14:57 - loss: 0.0118 - accuracy: 0.9922"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    X_train_data,\n",
    "    Y_train_data,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[train_1_callback, stop_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(X_validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13123, 5)\n"
     ]
    }
   ],
   "source": [
    "print(Y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.036349441274069e-05, 0.9958725571632385, 0.0026994943618774414, 5.295994196785614e-05, 0.004691628273576498], [2.9773944334010594e-05, 0.003400536486878991, 0.010829447768628597, 0.9982026219367981, 0.016583293676376343], [5.6502198276575655e-05, 0.9945985674858093, 0.0032556354999542236, 8.043862180784345e-05, 0.005636726040393114], [6.049039075151086e-05, 0.995907187461853, 0.002684086561203003, 5.308178879204206e-05, 0.004665063694119453], [2.980397221108433e-05, 0.003366216318681836, 0.010833054780960083, 0.9984875321388245, 0.016582727432250977], [5.761990541941486e-05, 0.9950159788131714, 0.003075510263442993, 7.571928290417418e-05, 0.005333354230970144], [2.980385943374131e-05, 0.003366404678672552, 0.010833293199539185, 0.9984781742095947, 0.016583174467086792], [5.764815796283074e-05, 0.9950259327888489, 0.0030711591243743896, 7.458451727870852e-05, 0.005326045677065849], [6.0811988078057766e-05, 0.9959931373596191, 0.0026457607746124268, 5.22411210113205e-05, 0.004598841071128845], [2.9778771931887604e-05, 0.0033946186304092407, 0.010827779769897461, 0.9983407258987427, 0.016577452421188354]]\n"
     ]
    }
   ],
   "source": [
    "list_1 = Y_predict.tolist()\n",
    "print(list_1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ar_1 = [1, 0, 0]\n",
    "ar_2 = [1, 0, 0]\n",
    "print(ar_1 == ar_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Y_p = Y_predict.tolist()\n",
    "Y_o = Y_validate_data.numpy().tolist()\n",
    "all_count = len(Y_p)\n",
    "correct_count = 0\n",
    "for i in range(all_count):\n",
    "    Y_p_arr = Y_p[i]\n",
    "    Y_o_arr = Y_o[i]\n",
    "    if Y_p_arr == Y_o_arr:\n",
    "        correct_count += 1\n",
    "print(correct_count/all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 52s 126ms/step - loss: 0.0420 - accuracy: 0.9803\n",
      "\n",
      "test loss 0.0419534407556057\n",
      "accuracy 0.9803398847579956\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_validate_data,Y_validate_data)\n",
    "print('\\ntest loss',loss)\n",
    "print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers' has no attribute 'CuDNNGRU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-df65c16a3276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                  metrics=['accuracy'])\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn_gru_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-df65c16a3276>\u001b[0m in \u001b[0;36mcudnn_gru_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     model = keras.Sequential([\n\u001b[1;32m      3\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40869\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCuDNNGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCuDNNGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'CuDNNGRU'"
     ]
    }
   ],
   "source": [
    "def cudnn_gru_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(input_dim=40869, output_dim=32, input_length=1000),\n",
    "        layers.CuDNNGRU(32, return_sequences=True),\n",
    "        layers.CuDNNGRU(1, activation='sigmoid', return_sequences=False)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                 loss=keras.losses.BinaryCrossentropy(),\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "model = cudnn_gru_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
